<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-face_authentication/embeddings" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.1">
<title data-rh="true">Exercise 02. ConvNeXt Model and Embedding Generation | Privacy Preserving Edge AI 101</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://edge-ai-101.wyliodrin.com/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://edge-ai-101.wyliodrin.com/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://edge-ai-101.wyliodrin.com/docs/face_authentication/embeddings"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Exercise 02. ConvNeXt Model and Embedding Generation | Privacy Preserving Edge AI 101"><meta data-rh="true" name="description" content="Overview"><meta data-rh="true" property="og:description" content="Overview"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://edge-ai-101.wyliodrin.com/docs/face_authentication/embeddings"><link data-rh="true" rel="alternate" href="https://edge-ai-101.wyliodrin.com/docs/face_authentication/embeddings" hreflang="en"><link data-rh="true" rel="alternate" href="https://edge-ai-101.wyliodrin.com/docs/face_authentication/embeddings" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Face Authentication","item":"https://edge-ai-101.wyliodrin.com/docs/category/face-authentication"},{"@type":"ListItem","position":2,"name":"Exercise 02. ConvNeXt Model and Embedding Generation","item":"https://edge-ai-101.wyliodrin.com/docs/face_authentication/embeddings"}]}</script><link rel="stylesheet" href="/assets/css/styles.1744e8a0.css">
<script src="/assets/js/runtime~main.53bc5ccc.js" defer="defer"></script>
<script src="/assets/js/main.0fe065e6.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Privacy Preserving Edge AI 101" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="Privacy Preserving Edge AI 101" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Edge AI 101</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/welcome">Workshop</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/Wyliodrin/edge-ai-101" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/welcome"><span title="Edge AI Workshop" class="linkLabel_WmDU">Edge AI Workshop</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/docs/category/face-authentication"><span title="Face Authentication" class="categoryLinkLabel_W154">Face Authentication</span></a><button aria-label="Collapse sidebar category &#x27;Face Authentication&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/face_authentication/"><span title="Overview" class="linkLabel_WmDU">Overview</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/face_authentication/image_processing"><span title="Exercise 01. Image Processing and Normalization" class="linkLabel_WmDU">Exercise 01. Image Processing and Normalization</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/face_authentication/embeddings"><span title="Exercise 02. ConvNeXt Model and Embedding Generation" class="linkLabel_WmDU">Exercise 02. ConvNeXt Model and Embedding Generation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/face_authentication/similarity"><span title="Exercise 03: Cosine Similarity for Face Authentication" class="linkLabel_WmDU">Exercise 03: Cosine Similarity for Face Authentication</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/face_authentication/local_storage"><span title="Exercise 04: Local File Storage for Face Embeddings" class="linkLabel_WmDU">Exercise 04: Local File Storage for Face Embeddings</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/face_authentication/retrieval"><span title="Exercise 05: Vector Retrieval and Similarity Search" class="linkLabel_WmDU">Exercise 05: Vector Retrieval and Similarity Search</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/face_authentication/full_application"><span title="Exercise 06: Complete Face Authentication System" class="linkLabel_WmDU">Exercise 06: Complete Face Authentication System</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/face_authentication/cheatsheet"><span title="Third-Party Libraries Cheatsheet for Face Auth Workshop" class="linkLabel_WmDU">Third-Party Libraries Cheatsheet for Face Auth Workshop</span></a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/chat_with_llm"><span title="Chat With LLM" class="linkLabel_WmDU">Chat With LLM</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/docs/category/face-authentication"><span>Face Authentication</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Exercise 02. ConvNeXt Model and Embedding Generation</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Exercise 02. ConvNeXt Model and Embedding Generation</h1></header>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="overview">Overview<a href="#overview" class="hash-link" aria-label="Direct link to Overview" title="Direct link to Overview" translate="no">​</a></h2>
<p>This exercise teaches you how to load a pre-trained ConvNeXt model and use it to generate face embeddings. You&#x27;ll implement two key functions: <code>build_model()</code> to load the model and <code>compute_embedding()</code> to generate feature vectors from facial images.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-convnext">What is ConvNeXt?<a href="#what-is-convnext" class="hash-link" aria-label="Direct link to What is ConvNeXt?" title="Direct link to What is ConvNeXt?" translate="no">​</a></h2>
<p>ConvNeXt (Convolution meets NeXt) is a modern convolutional neural network architecture that bridges the gap between traditional CNNs and Vision Transformers (ViTs). Introduced by Facebook AI Research in 2022, ConvNeXt modernizes the standard ResNet architecture by incorporating design choices inspired by Vision Transformers.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="key-features-of-convnext">Key Features of ConvNeXt:<a href="#key-features-of-convnext" class="hash-link" aria-label="Direct link to Key Features of ConvNeXt:" title="Direct link to Key Features of ConvNeXt:" translate="no">​</a></h3>
<ul>
<li><strong>Pure Convolutional Architecture</strong>: Uses only convolutions, no self-attention mechanisms</li>
<li><strong>Modernized ResNet Design</strong>: Incorporates macro and micro design choices from ViTs</li>
<li><strong>Competitive Performance</strong>: Achieves performance comparable to Swin Transformers</li>
<li><strong>Efficiency</strong>: Maintains the computational efficiency of traditional CNNs</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="convnext-atto-variant">ConvNeXt-Atto Variant:<a href="#convnext-atto-variant" class="hash-link" aria-label="Direct link to ConvNeXt-Atto Variant:" title="Direct link to ConvNeXt-Atto Variant:" translate="no">​</a></h3>
<p>We use <strong>ConvNeXt-Atto</strong>, an ultra-lightweight variant that provides excellent performance for face recognition tasks while being computationally efficient.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-are-face-embeddings">What are Face Embeddings?<a href="#what-are-face-embeddings" class="hash-link" aria-label="Direct link to What are Face Embeddings?" title="Direct link to What are Face Embeddings?" translate="no">​</a></h2>
<p>Embeddings are dense, low-dimensional vector representations that capture the essential characteristics of a face in numerical form.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="purpose-of-face-embeddings">Purpose of Face Embeddings:<a href="#purpose-of-face-embeddings" class="hash-link" aria-label="Direct link to Purpose of Face Embeddings:" title="Direct link to Purpose of Face Embeddings:" translate="no">​</a></h3>
<ol>
<li><strong>Dimensionality Reduction</strong>: Convert 224×224×3 images (~150K pixels) to compact vectors (~320 dimensions)</li>
<li><strong>Feature Extraction</strong>: Capture essential facial characteristics (eye shape, nose structure, etc.)</li>
<li><strong>Similarity Computation</strong>: Enable mathematical comparison between different faces</li>
<li><strong>Efficient Storage</strong>: Store compact representations instead of full images</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="properties-of-good-face-embeddings">Properties of Good Face Embeddings:<a href="#properties-of-good-face-embeddings" class="hash-link" aria-label="Direct link to Properties of Good Face Embeddings:" title="Direct link to Properties of Good Face Embeddings:" translate="no">​</a></h3>
<ul>
<li><strong>Discriminative</strong>: Different people produce different embeddings</li>
<li><strong>Robust</strong>: Similar embeddings for the same person under different conditions</li>
<li><strong>Compact</strong>: Much smaller than original images</li>
<li><strong>Comparable</strong>: Can be compared using mathematical similarity metrics</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="your-tasks">Your Tasks<a href="#your-tasks" class="hash-link" aria-label="Direct link to Your Tasks" title="Direct link to Your Tasks" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="task-1-implement-build_model">Task 1: Implement <code>build_model()</code><a href="#task-1-implement-build_model" class="hash-link" aria-label="Direct link to task-1-implement-build_model" title="Direct link to task-1-implement-build_model" translate="no">​</a></h3>
<div class="language-rust codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-rust codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">pub</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">fn</span><span class="token plain"> </span><span class="token function-definition function" style="color:#d73a49">build_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">-&gt;</span><span class="token plain"> </span><span class="token class-name">Result</span><span class="token operator" style="color:#393A34">&lt;</span><span class="token class-name">Func</span><span class="token operator" style="color:#393A34">&lt;</span><span class="token lifetime-annotation symbol" style="color:#36acaa">&#x27;static</span><span class="token operator" style="color:#393A34">&gt;&gt;</span><br></span></code></pre></div></div>
<p>This function should:</p>
<ol>
<li><strong>Download Model</strong>: Use Hugging Face Hub API to get &quot;timm/convnext_atto.d2_in1k&quot;</li>
<li><strong>Load Weights</strong>: Load the SafeTensors model file</li>
<li><strong>Create Model</strong>: Build ConvNeXt without the final classification layer</li>
<li><strong>Return Function</strong>: Return a callable model function</li>
</ol>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="why-without-final-layer">Why &quot;Without Final Layer&quot;?<a href="#why-without-final-layer" class="hash-link" aria-label="Direct link to Why &quot;Without Final Layer&quot;?" title="Direct link to Why &quot;Without Final Layer&quot;?" translate="no">​</a></h4>
<p>The original ConvNeXt model was trained for ImageNet classification (1000 classes). It has:</p>
<ul>
<li><strong>Feature Extraction Layers</strong>: Extract meaningful patterns from images</li>
<li><strong>Final Classification Layer</strong>: Maps features to 1000 ImageNet class probabilities</li>
</ul>
<p>For face embeddings, we want:</p>
<ul>
<li>✅ <strong>Feature Extraction</strong>: The rich feature representations (embeddings)</li>
<li>❌ <strong>Classification</strong>: We don&#x27;t need ImageNet class predictions</li>
</ul>
<p>By removing the final layer, we get the raw feature vectors (embeddings) that capture facial characteristics, which we can then use for similarity comparison: Use <code>convnext::convnext_no_final_layer</code> - CHECK CANDLE CONVNEXT</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="implementation-approach">Implementation Approach:<a href="#implementation-approach" class="hash-link" aria-label="Direct link to Implementation Approach:" title="Direct link to Implementation Approach:" translate="no">​</a></h4>
<ul>
<li>Use Hugging Face Hub API for model download</li>
<li>Load model weights with VarBuilder</li>
<li>Create ConvNeXt architecture without classification head</li>
<li>Return the model as a callable function</li>
</ul>
<p><strong>Hint</strong>: Check the CHEATSHEET.md for HuggingFace API patterns and model loading.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="task-2-implement-compute_embedding">Task 2: Implement <code>compute_embedding()</code><a href="#task-2-implement-compute_embedding" class="hash-link" aria-label="Direct link to task-2-implement-compute_embedding" title="Direct link to task-2-implement-compute_embedding" translate="no">​</a></h3>
<div class="language-rust codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-rust codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">pub</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">fn</span><span class="token plain"> </span><span class="token function-definition function" style="color:#d73a49">compute_embedding</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&amp;</span><span class="token class-name">Func</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> image</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&amp;</span><span class="token class-name">Tensor</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">-&gt;</span><span class="token plain"> </span><span class="token class-name">Result</span><span class="token operator" style="color:#393A34">&lt;</span><span class="token class-name">Tensor</span><span class="token operator" style="color:#393A34">&gt;</span><br></span></code></pre></div></div>
<p>This function should:</p>
<ol>
<li><strong>Handle Input Format</strong>: Check if input is single image or batch</li>
<li><strong>Add Batch Dimension</strong>: If needed, ensure proper tensor dimensions</li>
<li><strong>Forward Pass</strong>: Run the image through the model</li>
<li><strong>Return Embeddings</strong>: Return the feature vectors</li>
</ol>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="implementation-approach-1">Implementation Approach:<a href="#implementation-approach-1" class="hash-link" aria-label="Direct link to Implementation Approach:" title="Direct link to Implementation Approach:" translate="no">​</a></h4>
<ul>
<li>Check tensor dimensions to determine if batching is needed</li>
<li>Ensure input tensor has the correct shape for the model</li>
<li>Use the model&#x27;s forward method to generate embeddings</li>
<li>Return the resulting embedding tensor</li>
</ul>
<p><strong>Hint</strong>: Models typically expect batch dimensions. Check the CHEATSHEET.md for tensor dimension handling.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="technical-details">Technical Details<a href="#technical-details" class="hash-link" aria-label="Direct link to Technical Details" title="Direct link to Technical Details" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="model-architecture">Model Architecture:<a href="#model-architecture" class="hash-link" aria-label="Direct link to Model Architecture:" title="Direct link to Model Architecture:" translate="no">​</a></h3>
<ul>
<li><strong>Input</strong>: 224×224×3 RGB images (ImageNet normalized)</li>
<li><strong>Output</strong>: 768-dimensional embedding vectors</li>
<li><strong>Weights</strong>: Pre-trained on ImageNet dataset</li>
<li><strong>Format</strong>: SafeTensors for efficient loading</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="tensor-shapes">Tensor Shapes:<a href="#tensor-shapes" class="hash-link" aria-label="Direct link to Tensor Shapes:" title="Direct link to Tensor Shapes:" translate="no">​</a></h3>
<ul>
<li><strong>Single Image Input</strong>: <code>[3, 224, 224]</code> → <code>[1, 3, 224, 224]</code> (add batch dim)</li>
<li><strong>Batch Input</strong>: <code>[N, 3, 224, 224]</code> → <code>[N, 3, 224, 224]</code> (keep as is)</li>
<li><strong>Output</strong>: <code>[N, 768]</code> where N is batch size</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="key-dependencies">Key Dependencies:<a href="#key-dependencies" class="hash-link" aria-label="Direct link to Key Dependencies:" title="Direct link to Key Dependencies:" translate="no">​</a></h3>
<ul>
<li><code>hf_hub</code> - Download models from Hugging Face</li>
<li><code>candle_transformers::models::convnext</code> - ConvNeXt implementation</li>
<li><code>candle_nn::VarBuilder</code> - Load model weights</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="testing">Testing<a href="#testing" class="hash-link" aria-label="Direct link to Testing" title="Direct link to Testing" translate="no">​</a></h2>
<p>The test verifies that:</p>
<ul>
<li>Model loads successfully from Hugging Face</li>
<li>Embedding computation works with preprocessed images</li>
<li>Output tensor has the correct batch dimension</li>
</ul>
<p>Run the test with:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cargo test</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="expected-behavior">Expected Behavior<a href="#expected-behavior" class="hash-link" aria-label="Direct link to Expected Behavior" title="Direct link to Expected Behavior" translate="no">​</a></h2>
<p>After successful implementation:</p>
<ul>
<li><code>build_model()</code> downloads and loads the ConvNeXt-Atto model</li>
<li><code>compute_embedding()</code> processes images and returns 768-dimensional embeddings</li>
<li>The model handles both single images and batches automatically</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="next-steps">Next Steps<a href="#next-steps" class="hash-link" aria-label="Direct link to Next Steps" title="Direct link to Next Steps" translate="no">​</a></h2>
<p>After completing this exercise, you&#x27;ll be ready to:</p>
<ul>
<li>Learn similarity computation between embeddings (Exercise 03)</li>
<li>Understand how these embeddings enable face recognition</li>
<li>Build storage systems for embedding databases (Exercise 04)</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="references">References<a href="#references" class="hash-link" aria-label="Direct link to References" title="Direct link to References" translate="no">​</a></h2>
<ul>
<li><strong>ConvNeXt Paper</strong>: <a href="https://arxiv.org/abs/2201.03545" target="_blank" rel="noopener noreferrer">A ConvNet for the 2020s</a></li>
<li><strong>Hugging Face Model</strong>: <a href="https://huggingface.co/timm/convnext_atto.d2_in1k" target="_blank" rel="noopener noreferrer">timm/convnext_atto.d2_in1k</a></li>
<li><strong>Candle ConvNeXt</strong>: <a href="https://github.com/huggingface/candle/blob/main/candle-transformers/src/models/convnext.rs" target="_blank" rel="noopener noreferrer">GitHub Implementation</a></li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/Wyliodrin/edge-ai-101/edit/main/docs/face_authentication/2_embeddings.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/face_authentication/image_processing"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Exercise 01. Image Processing and Normalization</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/face_authentication/similarity"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Exercise 03: Cosine Similarity for Face Authentication</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#overview" class="table-of-contents__link toc-highlight">Overview</a></li><li><a href="#what-is-convnext" class="table-of-contents__link toc-highlight">What is ConvNeXt?</a><ul><li><a href="#key-features-of-convnext" class="table-of-contents__link toc-highlight">Key Features of ConvNeXt:</a></li><li><a href="#convnext-atto-variant" class="table-of-contents__link toc-highlight">ConvNeXt-Atto Variant:</a></li></ul></li><li><a href="#what-are-face-embeddings" class="table-of-contents__link toc-highlight">What are Face Embeddings?</a><ul><li><a href="#purpose-of-face-embeddings" class="table-of-contents__link toc-highlight">Purpose of Face Embeddings:</a></li><li><a href="#properties-of-good-face-embeddings" class="table-of-contents__link toc-highlight">Properties of Good Face Embeddings:</a></li></ul></li><li><a href="#your-tasks" class="table-of-contents__link toc-highlight">Your Tasks</a><ul><li><a href="#task-1-implement-build_model" class="table-of-contents__link toc-highlight">Task 1: Implement <code>build_model()</code></a></li><li><a href="#task-2-implement-compute_embedding" class="table-of-contents__link toc-highlight">Task 2: Implement <code>compute_embedding()</code></a></li></ul></li><li><a href="#technical-details" class="table-of-contents__link toc-highlight">Technical Details</a><ul><li><a href="#model-architecture" class="table-of-contents__link toc-highlight">Model Architecture:</a></li><li><a href="#tensor-shapes" class="table-of-contents__link toc-highlight">Tensor Shapes:</a></li><li><a href="#key-dependencies" class="table-of-contents__link toc-highlight">Key Dependencies:</a></li></ul></li><li><a href="#testing" class="table-of-contents__link toc-highlight">Testing</a></li><li><a href="#expected-behavior" class="table-of-contents__link toc-highlight">Expected Behavior</a></li><li><a href="#next-steps" class="table-of-contents__link toc-highlight">Next Steps</a></li><li><a href="#references" class="table-of-contents__link toc-highlight">References</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/welcome">Workshop</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/Wyliodrin/edge-ai-101" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Wyliodrin SRL. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>