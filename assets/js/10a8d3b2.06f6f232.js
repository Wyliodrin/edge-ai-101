"use strict";(globalThis.webpackChunkedge_ai=globalThis.webpackChunkedge_ai||[]).push([[700],{1584:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"face_authentication/cheatsheet","title":"Third-Party Libraries Cheatsheet for Face Auth Workshop","description":"This cheatsheet covers the essential parts of candle_, image, and serde* libraries used across exercises 01-05.","source":"@site/docs/face_authentication/cheatsheet.md","sourceDirName":"face_authentication","slug":"/face_authentication/cheatsheet","permalink":"/docs/face_authentication/cheatsheet","draft":false,"unlisted":false,"editUrl":"https://github.com/Wyliodrn/edge-ai-101/tree/main/docs/face_authentication/cheatsheet.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Exercise 06: Complete Face Authentication System","permalink":"/docs/face_authentication/full_application"},"next":{"title":"Chat With LLM","permalink":"/docs/chat_with_llm"}}');var r=s(4848),t=s(8453);const a={},l="Third-Party Libraries Cheatsheet for Face Auth Workshop",o={},d=[{value:"\ud83d\udd25 Candle Framework",id:"-candle-framework",level:2},{value:"Basic Tensor Operations",id:"basic-tensor-operations",level:3},{value:"Creating Tensors",id:"creating-tensors",level:4},{value:"Tensor Shape Manipulation",id:"tensor-shape-manipulation",level:4},{value:"Data Type Conversions",id:"data-type-conversions",level:4},{value:"Mathematical Operations",id:"mathematical-operations",level:4},{value:"Reduction Operations",id:"reduction-operations",level:4},{value:"Extracting Values",id:"extracting-values",level:4},{value:"L2 Normalization (Essential for Embeddings)",id:"l2-normalization-essential-for-embeddings",level:3},{value:"Cosine Similarity Building Blocks",id:"cosine-similarity-building-blocks",level:3},{value:"Model Loading &amp; Usage",id:"model-loading--usage",level:3},{value:"\ud83d\uddbc\ufe0f Image Processing",id:"\ufe0f-image-processing",level:2},{value:"Dependencies",id:"dependencies",level:3},{value:"Essential Imports",id:"essential-imports",level:3},{value:"Loading and Processing Images",id:"loading-and-processing-images",level:3},{value:"Filter Types",id:"filter-types",level:3},{value:"\ud83d\udce6 Serde (Serialization/Deserialization)",id:"-serde-serializationdeserialization",level:2},{value:"Defining Serializable Structs",id:"defining-serializable-structs",level:3},{value:"JSON Serialization",id:"json-serialization",level:3},{value:"JSON Deserialization",id:"json-deserialization",level:3},{value:"Working with DateTime",id:"working-with-datetime",level:3},{value:"Working with UUIDs",id:"working-with-uuids",level:3},{value:"\ud83d\ude80 Performance Tips",id:"-performance-tips",level:2},{value:"\u26a0\ufe0f Common Pitfalls",id:"\ufe0f-common-pitfalls",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"third-party-libraries-cheatsheet-for-face-auth-workshop",children:"Third-Party Libraries Cheatsheet for Face Auth Workshop"})}),"\n",(0,r.jsxs)(n.p,{children:["This cheatsheet covers the essential parts of ",(0,r.jsx)(n.strong,{children:"candle_"}),"*, ",(0,r.jsx)(n.strong,{children:"image"}),", and ",(0,r.jsx)(n.strong,{children:"serde"})," libraries used across exercises 01-05."]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-candle-framework",children:"\ud83d\udd25 Candle Framework"}),"\n",(0,r.jsx)(n.h3,{id:"basic-tensor-operations",children:"Basic Tensor Operations"}),"\n",(0,r.jsx)(n.h4,{id:"creating-tensors",children:"Creating Tensors"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-rust",children:"// From vector with shape\nlet data: Vec<u8> = image_data;\nlet tensor = Tensor::from_vec(data, (height, width, channels), &Device::Cpu)?;\n\n// From array/slice\nlet mean = [0.485, 0.456, 0.406];\nlet mean_tensor = Tensor::new(&mean, &Device::Cpu)?;\n\n// Reshape tensor\nlet reshaped = tensor.reshape((3, 1, 1))?;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"tensor-shape-manipulation",children:"Tensor Shape Manipulation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-rust",children:"// Permute dimensions (e.g., HWC to CHW)\nlet tensor = tensor.permute((2, 0, 1))?;\n\n// Add batch dimension\nlet batched = tensor.unsqueeze(0)?;\n\n// Remove singleton dimensions\nlet squeezed = tensor.squeeze(0)?.squeeze(0)?;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"data-type-conversions",children:"Data Type Conversions"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-rust",children:"// Convert to different data types\nlet float_tensor = tensor.to_dtype(DType::F32)?;\n\n// Scale values (e.g., 0-255 to 0-1)\nlet normalized = tensor.to_dtype(DType::F32)? / 255.0;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"mathematical-operations",children:"Mathematical Operations"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Broadcasting Operations"}),": These automatically expand tensors to compatible shapes for element-wise operations."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-rust",children:'// Broadcasting rules: smaller tensors are "stretched" to match larger ones\n// Example: (3, 224, 224) + (3, 1, 1) = (3, 224, 224)\n// The (3, 1, 1) tensor gets repeated across all 224x224 pixels\n\nlet result = tensor1.broadcast_add(&tensor2)?;     // Addition\nlet result = tensor1.broadcast_sub(&tensor2)?;     // Subtraction\nlet result = tensor1.broadcast_mul(&tensor2)?;     // Multiplication\nlet result = tensor1.broadcast_div(&tensor2)?;     // Division\n\n// Matrix multiplication (no broadcasting - strict dimension requirements)\nlet result = tensor_a.matmul(&tensor_b)?;\n\n// Transpose swaps two dimensions\nlet transposed = tensor.transpose(0, 1)?;  // Swap dims 0 and 1\n'})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"How Broadcasting Works"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Dimensions are aligned from the right (trailing dimensions first)"}),"\n",(0,r.jsx)(n.li,{children:"Missing dimensions are treated as size 1"}),"\n",(0,r.jsx)(n.li,{children:"Dimensions of size 1 are stretched to match the other tensor"}),"\n",(0,r.jsxs)(n.li,{children:["Example: ",(0,r.jsx)(n.code,{children:"(256,)"})," + ",(0,r.jsx)(n.code,{children:"(3, 224, 224)"})," becomes ",(0,r.jsx)(n.code,{children:"(1, 1, 256)"})," + ",(0,r.jsx)(n.code,{children:"(3, 224, 224)"})," \u2192 ",(0,r.jsx)(n.code,{children:"(3, 224, 224)"})]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"reduction-operations",children:"Reduction Operations"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsxs)(n.strong,{children:["What ",(0,r.jsx)(n.code,{children:"keepdim"})," means"]}),": Maintains the original number of dimensions by keeping reduced dims as size 1."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-rust",children:"// sum_keepdim example:\n// Input:  (2, 3, 4) tensor\n// .sum(1) \u2192 (2, 4)        # dimension 1 disappears\n// .sum_keepdim(1) \u2192 (2, 1, 4)  # dimension 1 becomes size 1\n\nlet sum = tensor.sum_keepdim(1)?;  // Sum along dim 1, keep dim structure\n\n// Element-wise operations\nlet sqrt_tensor = tensor.sqrt()?;   // \u221ax for each element\nlet squared = tensor.sqr()?;        // x\xb2 for each element\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Why keepdim matters"}),": Preserves tensor shape for broadcasting operations. Without it, you can't broadcast the result back to the original tensor shape."]}),"\n",(0,r.jsx)(n.h4,{id:"extracting-values",children:"Extracting Values"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-rust",children:"// Single scalar value\nlet scalar: f32 = tensor.to_vec0()?;\n\n// 1D vector\nlet values: Vec<f32> = tensor.to_vec1()?;\n\n// Flatten all dimensions and get vector\nlet flattened: Vec<f32> = tensor.flatten_all()?.to_vec1()?;\n"})}),"\n",(0,r.jsx)(n.h3,{id:"l2-normalization-essential-for-embeddings",children:"L2 Normalization (Essential for Embeddings)"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"What it does"}),": Scales vectors to unit length while preserving direction. Essential for cosine similarity."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Mathematical Formula"}),": ",(0,r.jsx)(n.code,{children:"normalized_vector = vector / ||vector||\u2082"})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Building Blocks"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-rust",children:"// Step by step operations you'll need:\n// 1. Square each element\nlet squared = tensor.sqr()?;\n\n// 2. Sum along dimension (keeping dimensions for broadcasting)\nlet sum_squared = tensor.sum_keepdim(1)?;\n\n// 3. Take square root to get L2 norm\nlet norm = sum_squared.sqrt()?;\n\n// 4. Divide original by norm (broadcasting)\nlet normalized = tensor.broadcast_div(&norm)?;\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Why use it"}),": After L2 normalization, ",(0,r.jsx)(n.code,{children:"||v||\u2082 = 1"}),", which means:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Cosine similarity becomes just a dot product"}),"\n",(0,r.jsx)(n.li,{children:"Removes magnitude bias - focuses only on direction"}),"\n",(0,r.jsx)(n.li,{children:"Essential for fair comparison of embeddings"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"cosine-similarity-building-blocks",children:"Cosine Similarity Building Blocks"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Mathematical Formula"}),": ",(0,r.jsx)(n.code,{children:"cosine_similarity = (A \xb7 B) / (||A|| \xd7 ||B||)"})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Key Operations"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-rust",children:"// Matrix multiplication for dot product\nlet dot_product = tensor_a.matmul(&tensor_b.transpose(0, 1)?)?;\n\n// Transpose for proper matrix multiplication\nlet transposed = tensor.transpose(0, 1)?;\n\n// Extract scalar from tensor\nlet scalar_value = tensor.squeeze(0)?.squeeze(0)?.to_vec0::<f32>()?;\n\n// For Vec<f32> similarity (alternative approach):\nlet dot: f32 = vec_a.iter().zip(vec_b.iter()).map(|(x, y)| x * y).sum();\nlet mag_a: f32 = vec_a.iter().map(|x| x * x).sum::<f32>().sqrt();\nlet mag_b: f32 = vec_b.iter().map(|x| x * x).sum::<f32>().sqrt();\n"})}),"\n",(0,r.jsx)(n.h3,{id:"model-loading--usage",children:"Model Loading & Usage"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Core Concepts"}),": Loading pre-trained models and running inference."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Hugging Face Hub API Building Blocks"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-rust",children:'// Download model from Hugging Face Hub\nlet api = hf_hub::api::sync::Api::new()?;\nlet api = api.model("model-name-here".to_string());\nlet model_file = api.get("model.safetensors")?;\n\n// Create VarBuilder from downloaded weights\nlet vb = unsafe {\n    VarBuilder::from_mmaped_safetensors(&[model_file], DType::F32, &device)?\n};\n\n// Load specific model architectures (examples):\n// ConvNeXt: convnext::convnext_no_final_layer(&config, vb)?\n// Other models have similar patterns\n'})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Inference Building Blocks"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-rust",children:"// Handle batch dimensions\nlet batched_input = if input.dim(0)? == 3 {  // Single image (C,H,W)\n    input.unsqueeze(0)?  // Add batch: (1,C,H,W)\n} else {\n    input.clone()  // Already batched (N,C,H,W)\n};\n\n// Forward pass through model\nlet output = model.forward(&batched_input)?;\n\n// Common model interfaces:\n// - Module::forward() for neural networks\n// - Func::forward() for functional models\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Key Points"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"VarBuilder"}),": Loads pre-trained weights from ",(0,r.jsx)(n.code,{children:".safetensors"})," files"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"Module::forward()"}),": Standard interface for neural network inference"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Batch Dimension"}),": Most models expect ",(0,r.jsx)(n.code,{children:"(batch_size, channels, height, width)"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Device Management"}),": Ensure model and input tensors are on same device"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"\ufe0f-image-processing",children:"\ud83d\uddbc\ufe0f Image Processing"}),"\n",(0,r.jsx)(n.h3,{id:"dependencies",children:"Dependencies"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-toml",children:'[dependencies]\nimage = "0.25.6"\n'})}),"\n",(0,r.jsx)(n.h3,{id:"essential-imports",children:"Essential Imports"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-rust",children:"use image::{ImageReader, ImageFormat};\n"})}),"\n",(0,r.jsx)(n.h3,{id:"loading-and-processing-images",children:"Loading and Processing Images"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-rust",children:"// Load image from file path\nlet img = image::ImageReader::open(path)?\n    .decode()?;\n\n// Resize image (multiple resize methods)\nlet img = img.resize_to_fill(\n    224,   // width\n    224,   // height\n    image::imageops::FilterType::Triangle,  // filter type\n);\n\n// Convert to RGB8 format\nlet img = img.to_rgb8();\n\n// Extract raw pixel data\nlet data: Vec<u8> = img.into_raw();  // Returns Vec<u8> with RGB values\n"})}),"\n",(0,r.jsx)(n.h3,{id:"filter-types",children:"Filter Types"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-rust",children:"// Available filter types for resizing\nimage::imageops::FilterType::Triangle    // Good general purpose\nimage::imageops::FilterType::Lanczos3   // High quality\nimage::imageops::FilterType::Nearest    // Fastest, pixelated\nimage::imageops::FilterType::CatmullRom  // Sharp results\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Key Concept"}),": The ",(0,r.jsx)(n.code,{children:"reshape((3, 1, 1))"})," creates tensors that broadcast across all pixels:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Original image: ",(0,r.jsx)(n.code,{children:"(3, 224, 224)"})," - 3 channels, 224\xd7224 pixels"]}),"\n",(0,r.jsxs)(n.li,{children:["Mean/Std: ",(0,r.jsx)(n.code,{children:"(3, 1, 1)"})," - 3 values, broadcasted to each pixel"]}),"\n",(0,r.jsx)(n.li,{children:"Result: Each of the 224\xd7224 pixels gets normalized using its channel's specific mean/std"}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-serde-serializationdeserialization",children:"\ud83d\udce6 Serde (Serialization/Deserialization)"}),"\n",(0,r.jsx)(n.h3,{id:"defining-serializable-structs",children:"Defining Serializable Structs"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-rust",children:"// Required derives for JSON serialization\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct YourStruct {\n    // Common field types:\n    pub id: String,                                    // String fields\n    pub name: String,\n    pub data: Vec<f32>,                               // Vector fields\n    pub timestamp: chrono::DateTime<chrono::Utc>,     // DateTime fields\n    pub metadata: HashMap<String, String>,            // HashMap fields\n}\n"})}),"\n",(0,r.jsx)(n.h3,{id:"json-serialization",children:"JSON Serialization"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-rust",children:'// Serialize to JSON string (pretty printed)\nlet json_string = serde_json::to_string_pretty(&records)?;\n\n// Serialize to JSON string (compact)\nlet json_string = serde_json::to_string(&records)?;\n\n// Write to file\nstd::fs::write("data.json", json_string)?;\n'})}),"\n",(0,r.jsx)(n.h3,{id:"json-deserialization",children:"JSON Deserialization"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-rust",children:'// Read from file\nlet content = std::fs::read_to_string("data.json")?;\n\n// Handle empty files\nif content.trim().is_empty() {\n    return Ok(Vec::new());\n}\n\n// Deserialize from JSON string\nlet records: Vec<EmbeddingRecord> = serde_json::from_str(&content)?;\n'})}),"\n",(0,r.jsx)(n.h3,{id:"working-with-datetime",children:"Working with DateTime"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-rust",children:"// Create current timestamp\nlet timestamp = chrono::Utc::now();\n\n// DateTime automatically serializes to ISO 8601 string in JSON\n"})}),"\n",(0,r.jsx)(n.h3,{id:"working-with-uuids",children:"Working with UUIDs"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-rust",children:"// Generate new UUID\nlet id = uuid::Uuid::new_v4().to_string();\n"})}),"\n",(0,r.jsx)(n.h2,{id:"-performance-tips",children:"\ud83d\ude80 Performance Tips"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Tensor Operations"}),": Use broadcast operations instead of loops when possible"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Memory Management"}),": Reuse tensors when possible, avoid unnecessary clones"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Model Loading"}),": Cache loaded models, don't reload for each inference"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Image Processing"}),": Consider batch processing multiple images at once"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Serialization"}),": Use ",(0,r.jsx)(n.code,{children:"serde_json::to_string_pretty"})," for debugging, regular ",(0,r.jsx)(n.code,{children:"to_string"})," for production"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"\ufe0f-common-pitfalls",children:"\u26a0\ufe0f Common Pitfalls"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Tensor Shapes"}),": Always check tensor dimensions before operations"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Data Types"}),": Be consistent with DType (F16 vs F32)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Error Handling"}),": Use ",(0,r.jsx)(n.code,{children:"?"})," operator and proper Result types"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Empty Files"}),": Always handle empty JSON files in deserialization"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Path Handling"}),": Use proper path validation for file operations"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>l});var i=s(6540);const r={},t=i.createContext(r);function a(e){const n=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);